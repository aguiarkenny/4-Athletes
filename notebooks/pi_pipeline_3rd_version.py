# -*- coding: utf-8 -*-
"""PI Pipeline - 3rd Version.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1faLXIt2cb25_8IxZ04RkmISNivhmJ_7K

## **Processamento dos vídeos e Extração de Dados**
"""

!pip uninstall -y numpy
!pip install numpy==1.23.5
!pip install --no-cache-dir mediapipe

#!/usr/bin/env python
# coding: utf-8
# Import das bibliotecas

import os
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd

from google.colab import drive
drive.mount('/content/drive')

# Para Google Colab, caso o vídeo esteja no Google Drive:
video_path = "/content/drive/MyDrive/Colab Notebooks/PI"  # Caminho correto do vídeo no Drive

# Caso o vídeo esteja na pasta local do Colab/Jupyter:
#video_path = "/content/exercicio.mp4"

# Inicializa o detector de pose
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

# Função para extrair dados de um vídeo

def extrair_dados_video(video_path, rotulo):
    cap = cv2.VideoCapture(video_path)
    dados = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        imagem_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        resultados = pose.process(imagem_rgb)

        if resultados.pose_landmarks:
            frame_data = []
            for lm in resultados.pose_landmarks.landmark:
                frame_data.extend([lm.x, lm.y, lm.z, lm.visibility])
            frame_data.append(rotulo)
            dados.append(frame_data)

    cap.release()
    return dados

# Processamento de todos os vídeos e extração dos dados com rótulo

dados_completos = []
arquivos = os.listdir(video_path)

for nome_arquivo in arquivos:
    if nome_arquivo.endswith(".mp4"):
        caminho_completo = os.path.join(video_path, nome_arquivo)

        # Determina o rótulo com base no nome do arquivo
        if "excerto" in nome_arquivo:
            rotulo = 1
        elif "exerrado" in nome_arquivo:
            rotulo = 0
        else:
            continue  # Ignora arquivos não rotulados corretamente

        print(f"Processando: {nome_arquivo} | Rótulo: {rotulo}")
        dados = extrair_dados_video(caminho_completo, rotulo)
        dados_completos.extend(dados)

# Salvamento dos dados rotulados

num_landmarks = 33
colunas = [f"{coord}_{i}" for i in range(num_landmarks) for coord in ['x', 'y', 'z', 'vis']] + ['rotulo']
df = pd.DataFrame(dados_completos, columns=colunas)
df.to_csv("/content/drive/MyDrive/Colab Notebooks/PI/dados_rotulados.csv", index=False)
print("Dataset salvo como dados_rotulados.csv")

df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/PI/dados_rotulados.csv")
df.describe()

import os
from pathlib import Path

video_folder = Path("/content/drive/MyDrive/Colab Notebooks/PI")  # Ajuste se necessário
videos = list(video_folder.glob("*.mp4"))
print(f"Total de vídeos encontrados: {len(videos)}")
for video in videos:
    print(video.name)

"""## **Treino e Teste do Modelo de Classificação**"""

# Importação das bibliotecas e leitura do arquivo
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import drive
drive.mount('/content/drive')

from sklearn.model_selection import train_test_split
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, classification_report

# Carregamento dos dados e visualização prévia
# Carrega o CSV rotulado
df = pd.read_csv("/content/drive/MyDrive/Colab Notebooks/PI/dados_rotulados.csv")
print(df.head())

# Verifica a distribuição dos rótulos
sns.countplot(data=df, x="rotulo")
plt.title("Distribuição das Execuções Corretas (1) e Incorretas (0)")
plt.show()

# Conferir os nomes de todas colunas
print(df.columns)

# Divisão em treino e teste
# Define X e y
X = df.drop(columns=["rotulo"])
y = df["rotulo"]

# Divisão entre treino e teste
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# Treinamento do modelo
# Cria e treina a árvore de decisão
model = DecisionTreeClassifier(random_state=42)
model.fit(X_train, y_train)

# Avaliação do Modelo
# Previsões
y_pred = model.predict(X_test)

# Acurácia
acc = accuracy_score(y_test, y_pred)
print(f"Acurácia: {acc:.2f}")

# Matriz de confusão
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Errado", "Correto"], yticklabels=["Errado", "Correto"])
plt.xlabel("Previsto")
plt.ylabel("Real")
plt.title("Matriz de Confusão")
plt.show()

# Relatório de classificação
print("Relatório de Classificação:")
print(classification_report(y_test, y_pred, target_names=["Errado", "Correto"]))

"""* ### **Estruturação Provisória**"""

# Reinstalação Provisória do Numpy e do MediaPipe - Se rodar o pipeline inteiro, não é necessário executar essa célula
!pip install numpy==1.23.5
!pip install --no-cache-dir mediapipe

# Reimportação das bibliotecas - Se rodar o pipeline inteiro, não é necessário executar essa célula

#!/usr/bin/env python
# coding: utf-8

import os
import cv2
import mediapipe as mp
import numpy as np
import pandas as pd

# Inicializa o detector de pose
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()
mp_drawing = mp.solutions.drawing_utils

"""* ### **Continuação**"""

# Previsão com vídeos de teste não rotulados
# Lista com caminhos dos vídeos de teste

videos_teste = [
    "/content/drive/MyDrive/Colab Notebooks/PI/testar1.mp4",
    "/content/drive/MyDrive/Colab Notebooks/PI/testar2.mp4"
]

for path in videos_teste:
    print(f"\nProcessando novo vídeo para predição: {os.path.basename(path)}")
    cap = cv2.VideoCapture(path)
    test_data = []

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            row = []
            for lm in landmarks:
                row.extend([lm.x, lm.y, lm.z, lm.visibility])
            test_data.append(row)

    cap.release()

    # Cria DataFrame e faz a previsão
    df_test = pd.DataFrame(test_data)
    if df_test.shape[1] == X_train.shape[1]:  # Garante que temos o mesmo número de colunas
        predictions = model.predict(df_test)
        proporcao_correto = np.mean(predictions)
        print(f"Proporção de frames classificados como 'correto': {proporcao_correto:.2f}")
    else:
        print("Número de colunas incompatível para predição.")

# Classificação em tempo real com visualização no vídeo
# Reaproveita a variável 'pose' que já foi inicializada anteriormente

# Lista com os caminhos dos vídeos de teste
videos_teste = [
    "/content/drive/MyDrive/Colab Notebooks/PI/testar1.mp4",
    "/content/drive/MyDrive/Colab Notebooks/PI/testar2.mp4"
]

for path in videos_teste:
    print(f"\nProcessando vídeo para predição com visualização: {os.path.basename(path)}")

    cap = cv2.VideoCapture(path)
    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
    fps = int(cap.get(cv2.CAP_PROP_FPS))
    fourcc = cv2.VideoWriter_fourcc(*'mp4v')

    out_path = f"/content/drive/MyDrive/Colab Notebooks/PI/saida_{os.path.basename(path)}"
    out = cv2.VideoWriter(out_path, fourcc, fps, (width, height))

    while cap.isOpened():
        ret, frame = cap.read()
        if not ret:
            break

        image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        results = pose.process(image_rgb)

        if results.pose_landmarks:
            landmarks = results.pose_landmarks.landmark
            row = []
            for lm in landmarks:
                row.extend([lm.x, lm.y, lm.z, lm.visibility])

            # Garante que temos a quantidade certa de colunas para predição
            if len(row) == X_train.shape[1]:
                pred = model.predict([row])[0]
                label = "CORRETO" if pred == 1 else "ERRADO"
                color = (0, 255, 0) if pred == 1 else (0, 0, 255)

                # Escreve a classificação no frame
                cv2.putText(frame, label, (50, 50), cv2.FONT_HERSHEY_SIMPLEX,
                            1.5, color, 3, cv2.LINE_AA)

            # Desenha landmarks
            mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)

        out.write(frame)

    cap.release()
    out.release()
    print(f"Vídeo com predição salva em: {out_path}")

"""## **Monitoramento de Movimentos nos Vídeos**"""

# Inicializa o detector de pose
mp_drawing = mp.solutions.drawing_utils
mp_pose = mp.solutions.pose
pose = mp_pose.Pose()

# Função para extrair calcular ângulos
def calculate_angle(a, b, c):
    a, b, c = np.array(a), np.array(b), np.array(c)
    radians = np.arctan2(c[1] - b[1], c[0] - b[0]) - np.arctan2(a[1] - b[1], a[0] - b[0])
    angle = np.abs(radians * 180.0 / np.pi)
    return 360 - angle if angle > 180 else angle

# Carrega o vídeo
cap = cv2.VideoCapture(video_path)

# Obtém as propriedades do vídeo
width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))
height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
fps = int(cap.get(cv2.CAP_PROP_FPS))

# Configuração do vídeo de saída
fourcc = cv2.VideoWriter_fourcc(*'mp4v')
out = cv2.VideoWriter('saida_exercicio.mp4', fourcc, fps, (width, height))

# Processamento do vídeo
data = []  # Lista para armazenar os dados
frame_count = 0
correct_frames = 0

while cap.isOpened():
    ret, frame = cap.read()
    if not ret:
        break

    frame_count += 1
    image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = pose.process(image)

    if results.pose_landmarks:
        mp_drawing.draw_landmarks(frame, results.pose_landmarks, mp_pose.POSE_CONNECTIONS)
        landmarks = results.pose_landmarks.landmark

        try:
            shoulder = [landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].x,
                        landmarks[mp_pose.PoseLandmark.LEFT_SHOULDER.value].y]
            elbow = [landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].x,
                     landmarks[mp_pose.PoseLandmark.LEFT_ELBOW.value].y]
            wrist = [landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].x,
                     landmarks[mp_pose.PoseLandmark.LEFT_WRIST.value].y]

            angle = calculate_angle(shoulder, elbow, wrist)

            # Calcula o ângulo do cotovelo
            angle = calculate_angle(shoulder, elbow, wrist)

             # Exibe o ângulo na tela
            cv2.putText(frame, str(int(angle)), tuple(np.multiply(elbow, [width, height]).astype(int)),
                        cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)

            # Armazena os dados
            print(f"Frame: {frame_count}, Ângulo: {int(angle)}")  # Verifica se os valores estão sendo calculados
            data.append([frame_count, int(angle)])

        except Exception as e:
            print(f"Erro ao processar frame {frame_count}: {e}")

    out.write(frame)

cap.release()
out.release()

# Salvamento dos Dados
df = pd.DataFrame(data, columns=["Frame", "Angulo"])
df.to_csv('dados_exercicio.csv', index=False)
print("Dados do exercício salvos em 'dados_exercicio.csv'.")

# Dataframe
df = pd.DataFrame(data, columns=["Frame", "Angulo"])
df.describe()